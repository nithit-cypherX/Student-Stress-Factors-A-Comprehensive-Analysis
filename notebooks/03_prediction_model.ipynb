{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../data/processed_data.csv')\n",
    "    print(\"CSV file loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'processed_data.csv' not found. Please make sure the file is in the same directory as your notebook or provide the correct path.\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anxiety_level  self_esteem  mental_health_history  depression  headache  \\\n",
      "0             14           20                      0          11         2   \n",
      "1             15            8                      1          15         5   \n",
      "2             12           18                      1          14         2   \n",
      "3             16           12                      1          15         4   \n",
      "4             16           28                      0           7         2   \n",
      "\n",
      "   blood_pressure  sleep_quality  breathing_problem  noise_level  \\\n",
      "0               1              2                  4            2   \n",
      "1               3              1                  4            3   \n",
      "2               1              2                  2            2   \n",
      "3               3              1                  3            4   \n",
      "4               3              5                  1            3   \n",
      "\n",
      "   living_conditions  ...  basic_needs  academic_performance  study_load  \\\n",
      "0                  3  ...            2                     3           2   \n",
      "1                  1  ...            2                     1           4   \n",
      "2                  2  ...            2                     2           3   \n",
      "3                  2  ...            2                     2           4   \n",
      "4                  2  ...            3                     4           3   \n",
      "\n",
      "   teacher_student_relationship  future_career_concerns  social_support  \\\n",
      "0                             3                       3               2   \n",
      "1                             1                       5               1   \n",
      "2                             3                       2               2   \n",
      "3                             1                       4               1   \n",
      "4                             1                       2               1   \n",
      "\n",
      "   peer_pressure  extracurricular_activities  bullying  stress_level  \n",
      "0              3                           3         2             1  \n",
      "1              4                           5         5             2  \n",
      "2              3                           2         2             1  \n",
      "3              4                           4         5             2  \n",
      "4              5                           0         5             1  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define student performance matrics with the most importance features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anxiety_level  stress_level  headache  safety  blood_pressure  \\\n",
      "0       0.666667           0.5       0.4     0.6             0.0   \n",
      "1       0.714286           1.0       1.0     0.4             1.0   \n",
      "2       0.571429           0.5       0.4     0.6             0.0   \n",
      "3       0.761905           1.0       0.8     0.4             1.0   \n",
      "4       0.761905           0.5       0.4     0.8             1.0   \n",
      "\n",
      "   teacher_student_relationship  bullying  academic_performance  \\\n",
      "0                           0.6       0.4                   0.6   \n",
      "1                           0.2       1.0                   0.2   \n",
      "2                           0.6       0.4                   0.4   \n",
      "3                           0.2       1.0                   0.4   \n",
      "4                           0.2       1.0                   0.8   \n",
      "\n",
      "   extracurricular_activities  sleep_quality  \n",
      "0                         0.6            0.4  \n",
      "1                         1.0            0.2  \n",
      "2                         0.4            0.4  \n",
      "3                         0.8            0.2  \n",
      "4                         0.0            1.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# STEP 1: Pick your top features\n",
    "top_features = ['anxiety_level', 'stress_level', 'headache', 'safety',\n",
    "                'blood_pressure', 'teacher_student_relationship', 'bullying', 'academic_performance' , 'extracurricular_activities' ]\n",
    "\n",
    "# STEP 2: Scale your data (MinMaxScaler to keep it 0-1 for easier plots)\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[top_features + ['sleep_quality']]),\n",
    "                         columns=top_features + ['sleep_quality'])\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   anxiety_level  stress_level  headache  safety  blood_pressure  \\\n",
      "0       0.666667           0.5       0.4     0.6             0.0   \n",
      "1       0.714286           1.0       1.0     0.4             1.0   \n",
      "2       0.571429           0.5       0.4     0.6             0.0   \n",
      "3       0.761905           1.0       0.8     0.4             1.0   \n",
      "4       0.761905           0.5       0.4     0.8             1.0   \n",
      "\n",
      "   teacher_student_relationship  bullying  academic_performance  \\\n",
      "0                           0.6       0.4                   0.6   \n",
      "1                           0.2       1.0                   0.2   \n",
      "2                           0.6       0.4                   0.4   \n",
      "3                           0.2       1.0                   0.4   \n",
      "4                           0.2       1.0                   0.8   \n",
      "\n",
      "   extracurricular_activities  sleep_quality  mentalHealth  relationship  \\\n",
      "0                         0.6            0.4      1.166667           1.2   \n",
      "1                         1.0            0.2      1.714286           0.4   \n",
      "2                         0.4            0.4      1.071429           1.0   \n",
      "3                         0.8            0.2      1.761905           0.6   \n",
      "4                         0.0            1.0      1.261905           1.0   \n",
      "\n",
      "   phihealth  acedemic_positive  acedemic_negative  \\\n",
      "0        0.4                0.6                0.4   \n",
      "1        2.0                1.0                1.0   \n",
      "2        0.4                0.4                0.4   \n",
      "3        1.8                0.8                1.0   \n",
      "4        1.4                0.0                1.0   \n",
      "\n",
      "   student_performance_weighted  student_performance_pca  \\\n",
      "0                      0.026667                -0.327508   \n",
      "1                     -0.342857                 1.294785   \n",
      "2                     -0.014286                -0.293200   \n",
      "3                     -0.272381                 1.121817   \n",
      "4                     -0.012381                 0.367425   \n",
      "\n",
      "   student_performance_pls  \n",
      "0                 0.516375  \n",
      "1                -3.043450  \n",
      "2                 0.622350  \n",
      "3                -2.472255  \n",
      "4                -0.363390  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "# STEP 3: Create feature combos (engineering)\n",
    "df_scaled['mentalHealth'] = df_scaled['anxiety_level'] + df_scaled['stress_level']\n",
    "df_scaled['relationship'] = df_scaled['teacher_student_relationship'] + df_scaled['academic_performance']\n",
    "df_scaled['phihealth'] = df_scaled['headache'] + df_scaled['blood_pressure']\n",
    "df_scaled['acedemic_positive'] = df_scaled['extracurricular_activities']\n",
    "df_scaled['acedemic_negative'] = df_scaled['bullying']\n",
    "\n",
    "df_scaled['student_performance_weighted'] = (\n",
    "    0.3 * df_scaled['academic_performance'] +  # direct academic\n",
    "    0.2 * df_scaled['teacher_student_relationship'] +  # social\n",
    "    -0.2 * df_scaled['stress_level'] +  # mental pressure\n",
    "    -0.2 * df_scaled['anxiety_level'] +\n",
    "    -0.1 * df_scaled['headache']  # health symptom\n",
    ")\n",
    "\n",
    "pca = PCA(n_components=1)\n",
    "df_scaled['student_performance_pca'] = pca.fit_transform(\n",
    "    df_scaled[['mentalHealth', 'relationship', 'phihealth']]\n",
    ")\n",
    "\n",
    "pls = PLSRegression(n_components=1)\n",
    "df_scaled['student_performance_pls'] = pls.fit_transform(\n",
    "    df_scaled[['mentalHealth', 'relationship', 'phihealth', 'acedemic_positive', 'acedemic_negative']],\n",
    "    df_scaled[['academic_performance']]\n",
    ")[0]\n",
    "\n",
    "\n",
    "# df_scaled['student_performance'] = (df_scaled['relationship'] + df_scaled['acedemic']) - (df_scaled['phihealth']  + df_scaled['mentalHealth'] )\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor model\n",
    "- ‚úÖ When it's better:\n",
    "- You want higher accuracy.\n",
    "- You have complex or noisy data.\n",
    "\n",
    "üöó How it's better:\n",
    "It uses multiple trees and averages them for better performance and less overfitting.\n",
    "\n",
    "Complex data, better accuracy\tAverages many trees for robust predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üå≤RandomForest MAE: 0.126, R¬≤: 0.604\n"
     ]
    }
   ],
   "source": [
    "# Use all combo features instead of only one\n",
    "# X = df_scaled[['mentalHealth', 'relationship', 'phihealth', 'acedemic']]  # better input\n",
    "# Optional: Try with PCA single feature too:\n",
    "X = df_scaled[['student_performance_pls'] ]\n",
    "\n",
    "y = df_scaled['sleep_quality']\n",
    "\n",
    "# Train-test split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y ,test_size=0.2 , random_state=42)\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "# Random Forest with tuning\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "}\n",
    "rf_search = RandomizedSearchCV(rf, param_distributions=param_grid, n_iter=5, cv=3, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "\n",
    "rf_best = rf_search.best_estimator_\n",
    "y_pred_rf = rf_best.predict(X_test)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"üå≤RandomForest MAE: {mae_rf:.3f}, R¬≤: {r2_rf:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor\n",
    "- When it's better:\n",
    "- You need state-of-the-art performance.\n",
    "- You‚Äôre okay with a bit more training time.\n",
    "\n",
    "üöó How it's better:\n",
    "It learns from mistakes of previous trees step-by-step, often giving top accuracy.\n",
    "\n",
    "High performance, Learns from previous errors, better accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "Best parameters found: {'learning_rate': 0.01, 'max_depth': 3, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 300, 'subsample': 1.0}\n",
      "üöÄ GradientBoosting MAE: 0.128, R¬≤: 0.637\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Initialize GradientBoostingRegressor\n",
    "model_gb = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],         # Number of boosting stages (trees)\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],      # How much each tree contributes to the model\n",
    "    \"max_depth\": [3, 5, 7],                   # Maximum depth of each tree\n",
    "    \"min_samples_split\": [2, 5, 10],          # Minimum number of samples required to split a node\n",
    "    \"min_samples_leaf\": [1, 2, 4],            # Minimum number of samples required at a leaf node\n",
    "    \"subsample\": [0.8, 0.9, 1.0]              # Fraction of samples used for each tree\n",
    "}\n",
    "# Use GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(estimator=model_gb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters from GridSearchCV\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_gb = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"üöÄ GradientBoosting MAE: {mae_gb:.3f}, R¬≤: {r2_gb:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost / LightGBM\n",
    "- When it's better:\n",
    "You're dealing with large datasets.\n",
    "\n",
    "You need fast and accurate results.\n",
    "\n",
    "üöó How it's better:\n",
    "These models are super fast and often win machine learning competitions for regression tasks.\n",
    "\n",
    "Big data, need for speed and power\tExtremely fast and accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "X = df_scaled[['student_performance_pls']]\n",
    "y = df_scaled['sleep_quality']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        verbose=False)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"üèéÔ∏èXGBoost (EarlyStop) MAE: {mae_xgb:.3f}, R¬≤: {r2_xgb:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train,\n",
    "         eval_set=[(X_test, y_test)])\n",
    "\n",
    "y_pred_lgbm = lgbm.predict(X_test)\n",
    "mae_lgbm = mean_absolute_error(y_test, y_pred_lgbm)\n",
    "r2_lgbm = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(f\"üí°LightGBM MAE: {mae_lgbm:.3f}, R¬≤: {r2_lgbm:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression\n",
    "- When it's better:\n",
    "Your dataset has many features (columns).\n",
    "\n",
    "There's multicollinearity (features are highly correlated).\n",
    "\n",
    "üö≤ How it's better:\n",
    "Ridge adds a penalty to large coefficients, preventing overfitting and making the model more stable.\n",
    "\n",
    "    Many features, correlated data\tPrevents overfitting, stabilizes coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "ridge = RidgeCV(alphas=[0.01, 0.1, 1.0, 10.0, 100.0], cv=3)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "mae_ridge = mean_absolute_error(y_test, y_pred_ridge)\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "\n",
    "print(f\"üèîÔ∏èRidgeCV MAE: {mae_ridge:.3f}, R¬≤: {r2_ridge:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression \n",
    "‚úÖ When it's better:\n",
    "You have many irrelevant or noisy features.\n",
    "\n",
    "You want feature selection built-in.\n",
    "\n",
    "üö≤ How it's better:\n",
    "Lasso automatically shrinks some coefficients to zero, removing unimportant features.\n",
    "\n",
    "    Feature selection\tAutomatically removes unimportant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lasso = LassoCV(alphas=[0.001, 0.01, 0.1, 1.0, 10.0], cv=3, random_state=42)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "mae_lasso = mean_absolute_error(y_test, y_pred_lasso)\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "\n",
    "print(f\"‚öôÔ∏èLassoCV MAE: {mae_lasso:.3f}, R¬≤: {r2_lasso:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet \n",
    "‚úÖ When it's better:\n",
    "You want a balance of Ridge's stability and Lasso's feature selection.\n",
    "\n",
    "Data is high-dimensional (many columns).\n",
    "\n",
    "üö≤ How it's better:\n",
    "ElasticNet combines the strengths of Ridge and Lasso into one model.\n",
    "\n",
    "A mix of Ridge and Lasso\tBalanced regularization and selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "elastic = ElasticNetCV(alphas=[0.01, 0.1, 1.0], l1_ratio=[0.2, 0.5, 0.8], cv=3, random_state=42)\n",
    "elastic.fit(X_train, y_train)\n",
    "\n",
    "y_pred_elastic = elastic.predict(X_test)\n",
    "mae_elastic = mean_absolute_error(y_test, y_pred_elastic)\n",
    "r2_elastic = r2_score(y_test, y_pred_elastic)\n",
    "\n",
    "print(f\"üß¨ElasticNetCV MAE: {mae_elastic:.3f}, R¬≤: {r2_elastic:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor\n",
    "‚úÖ When it's better:\n",
    "Data has non-linear relationships.\n",
    "\n",
    "You want interpretable rules (if-then).\n",
    "\n",
    "üöó How it's better:\n",
    "It splits data into decision paths and handles non-linearity very well.\n",
    "\n",
    "Complex data, better accuracy\tAverages many trees for robust predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "tree_search = RandomizedSearchCV(tree, param_distributions=param_grid, n_iter=5, cv=3, random_state=42)\n",
    "tree_search.fit(X_train, y_train)\n",
    "\n",
    "tree_best = tree_search.best_estimator_\n",
    "y_pred_tree = tree_best.predict(X_test)\n",
    "mae_tree = mean_absolute_error(y_test, y_pred_tree)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "\n",
    "print(f\"üå≥DecisionTree MAE: {mae_tree:.3f}, R¬≤: {r2_tree:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
